# Model Risk Management Framework for Machine Learning Models (Trustworthy AI)

**WORK IN PROGRESS**

This repository presents a quantitative approach to create a holistic validation framework for Artificial Intelligence systems. It reflects the nascent AI regulatory landscape and its expected near term development. The **Ethics Guidelines for Trustworthy Artificial Intelligence** presented by the High-Level Expert Group on AI put forward a set of 7 key requirements that AI systems should meet in order to be deemed trustworthy: 
 - Human agency and oversight, 
 - **Technical Robustness and safety**,
 - Privacy and data governance,
 - **Transparency**, 
 - **Diversity, non-discrimination and fairness**, 
 - Societal and environmental well-being, 
 - Accountability

We focus on the quantitative aspects of model interpretability, robustness, and fairness, while aiming for building models that satisfy these requirements without sacrificing a large amount of model performance. We present the framework around the use case of default prediction with the goal of predicting the probability a credit card client will default based on data from other customers from a bank.
